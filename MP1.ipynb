{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smXHK_llmOMj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.io import imread,imshow,imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Contents MP1\n",
    "- ### 1-D convolution (discrete) - [30 points]\n",
    "- ### 2-D convolution (discrete) - [40 points]\n",
    "- ### Edge detection in images using convolution filters - [30 points]\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D Convolution (Discrete)\n",
    "\n",
    "    A convolution is an integral that expresses the amount of overlap of one function g as it is shifted over another function f. It therefore \"blends\" one function with another. For example, in synthesis imaging, the measured dirty map is a convolution of the \"true\" CLEAN map with the dirty beam.\n",
    "\n",
    "[Tutorial](https://www.youtube.com/watch?v=yyTu0SXeW1M) 6:30\n",
    "![Definition of Discrete Convolution 1-D](./resources/convolution_1d_definition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By its definition (Eq 2), a convolution operation between two discrete finite arrays are to be done on an infinite range of index k ∈ Z from k = -inf to k = inf. \n",
    "\n",
    "As a convention, we will consider the array starts at k = 0, that is, the first element of the array A is A\\[0\\]. \n",
    "\n",
    "E.g.: Signal A: [2, -1, 6, 1, 7, -3, 2, 6]\n",
    "\n",
    "A[0] = 2, A[1] = -1, A[2] = 6, ..., A[7] = 6\n",
    "\n",
    "This conviniently goes along with the array indexing in python. But what to do for the undefined elements, such as A[-1] and A[8]? -1 and 8 are valid values for index k ∈ Z.\n",
    "\n",
    "We will assume any undefined element to be 0 in the array. We will go into further detail about this choice in the next few cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Manual 1-D Convolution Excercise - [5 points]\n",
    "\n",
    "With the definition above, calculate the results of convolutions of signals A, B, and C with Kernel H.\n",
    "\n",
    "Signal A: \\[2, -4, 6, 1, 7, -3, 2, 6\\]\n",
    "\n",
    "Signal B: \\[0, 1, 0, 1, 9, 3, -1\\]\n",
    "\n",
    "Signal C: \\[0, 0, 0, 0, 1, 0, 0, 0, 0\\]\n",
    "\n",
    "Kernel H: \\[1, 2, -1, 3\\]\n",
    "\n",
    "Hint: The result array might not start with index k == 0. Mark the starting index for each result. (See the Turotial Above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers: \n",
    "\n",
    "(\\* denotes convolution operator.)\n",
    "\n",
    "A * H = ?\n",
    "\n",
    "B * H = ?\n",
    "\n",
    "C * H = ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Convolution vs Cross-Correlation - [5 points]\n",
    "\n",
    "![Definition of Discrete Correlation Filtering](./resources/correlation_1d_definition.jpg)\n",
    "\n",
    "[1-D Convolution/Correlation Visualization](https://www.youtube.com/watch?v=O9-HN-yzsFQ) 0:36\n",
    "\n",
    "Look at the definition of cross-correlation (Eq 4) and the visualization of the convolution and the cross-correlation examples. Compare the two operations.\n",
    "\n",
    "What do you notice? In your words, how do the two operations differ from each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] 1-D Discrete Convolution in Python - [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many common math/science Python packages offer optimized implementation of convolution function. Below is an example of Numpy's convolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBg-46kcB1Ul",
    "outputId": "44553143-7aa4-442d-c940-19475e3f8203"
   },
   "outputs": [],
   "source": [
    "X = np.array([0, 1, 2, 3, 4])\n",
    "H = np.array([0, 0.5, 1])\n",
    "\n",
    "# Read: https://numpy.org/doc/stable/reference/generated/numpy.convolve.html\n",
    "Y = np.convolve(X, H, mode=\"full\")\n",
    "Y_reverse = np.convolve(H, X, mode=\"full\")\n",
    "\n",
    "print(Y)\n",
    "print(Y_reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets implement the 1-D convolution function corresponding to numpy's \"full\" mode in the cell below. However, the only numpy functions you can use are:\n",
    "```\n",
    "np.array()\n",
    "np.zeros()\n",
    "np.ones()\n",
    "```\n",
    "\n",
    "**Do not change the function signature (function name, return type, and input parameters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJdG8GLyE8_b"
   },
   "outputs": [],
   "source": [
    "def conv1d(X, H):\n",
    "    '''\n",
    "    Returns the result Y = X * H, where * is the 1-D convolution operator. (following variable convention in Eq 2)\n",
    "\n",
    "        Parameters:\n",
    "                X (array): Input data/signal\n",
    "                H (array): Convolution kernel/signal\n",
    "\n",
    "        Returns:\n",
    "                Y (array): Convolution result similar to \"full\" mode in np.convolve()\n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check your result by comparing it with ```np.convolve```. Notice that this is not a comprehensive test. You are encouraged to make your own testcases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYpROa6AJysU",
    "outputId": "41081a9a-9c6e-407d-b600-b31283d62c64"
   },
   "outputs": [],
   "source": [
    "print(\"Correct (Numpy) Result:\")\n",
    "np_result = np.convolve(X, H, mode=\"full\")\n",
    "print(np_result)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Your Answer:\")\n",
    "your_result = conv1d(X, H)\n",
    "print(your_result)\n",
    "\n",
    "\n",
    "print(\"\\nYour result is {}\".format(\"correct!\" if np.array_equal(np_result, your_result) else \"incorrect.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dd5gsIdRUmn"
   },
   "source": [
    "# 2-D Convolution (Discrete)\n",
    "\n",
    "![2-D Discrete Convolution Definition](./resources/convolution_2d_definition.jpg)\n",
    "\n",
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch this 2-D discrete convolution example. [2-D Discrete Convolution Example](https://www.youtube.com/watch?v=_iZ3Q7VXiGI) \n",
    "\n",
    "Notice two things:\n",
    "\n",
    "1. The convolution kernel is already flipped. By definition, the result of ```A (*convolve) B ``` is exactly the same as ```A (*cross-correlate) B'```, where ```B'``` is ```B``` flipped. [Read a little more about this](https://cs.stackexchange.com/questions/11591/2d-convolution-flipping-the-kernel). Therefore what we really see in the video is the cross-correlation of the Input image and the flipped kernel. This will continue to be the theme in this tutorial and in many discussions about convolution you'll see online.\n",
    "2. The presenter uses the \"valid\" padding mode, meaning he will not consider the undefined elements of the input (no padding around the input). This contrasts other padding modes \"full\" and \"same\". You can read more about these modes at https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "[Convolution Padding Explanation](https://www.youtube.com/watch?v=6v05kAtV1M0) 11:13\n",
    "\n",
    "![Different Padding Modes](./resources/0rs9l.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] 2-D Discrete Convolution in Python - [40 points]\n",
    "\n",
    "Now go ahead and implement the 2-D convolution function in the cell below. However, the only numpy functions you can use are:\n",
    "```\n",
    "np.array()\n",
    "np.flipud()\n",
    "np.fliplr()\n",
    "np.zeros()\n",
    "np.ones()\n",
    "np.sum()\n",
    "```\n",
    "Typically, in image processing tasks, we want to preserve size of input after the convolution operation. **Therefore, your code should implement the \"same\" mode convolution here. You can assume stride=1 and padding fillvalue=0. You will need to figure out how much 0-padding you need based on the difference in the image and kernel size.** You can review https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html for reference.\n",
    "\n",
    "**Do not change the function signature (function name, return type, and input parameters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(image, kernel):\n",
    "    '''\n",
    "    Returns the result Y = image * kernel, where * is the 2-D convolution operator.\n",
    "\n",
    "        Parameters:\n",
    "                image (ndarray): 2-D input image/signal\n",
    "                kernel (ndarray): 2-D convolution kernel/signal\n",
    "\n",
    "        Returns:\n",
    "                Y (ndarray): 2-D convolution result similar to \"same\" mode in scipy/numpy.\n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check your result by comparing it with ```scipy.signal.convolve2d```.\n",
    "\n",
    "Notice that this is not a comprehensive test. You are encouraged to make your own testcases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOjeW-selHe2",
    "outputId": "bd37ac78-f92c-4306-f462-e16d3ff24f87"
   },
   "outputs": [],
   "source": [
    "image = np.array([[1,2,3],[2,3,4],[4,4,4],[-1,0,1]]) # 4 x 3\n",
    "kernel = np.array([[1,2],[2,3.7]]) # 2 x 2\n",
    "\n",
    "print(\"Correct (Scipy) Result:\")\n",
    "from scipy.signal import convolve2d\n",
    "np_result = convolve2d(image, kernel, mode=\"same\", boundary='fill', fillvalue=0)\n",
    "print(np_result) # 4 x 3 - same as input since mode=\"same\"\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Your Answer:\")\n",
    "your_result = conv2d(image, kernel)\n",
    "print(your_result)\n",
    "\n",
    "print(\"\\nYour result is {}\".format(\"correct!\" if np.array_equal(\n",
    "    np_result, your_result) else \"incorrect.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utvGd8zQB1qi"
   },
   "source": [
    "# Edge Detection in Images with Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download these sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HczMQR6bob_y",
    "outputId": "d8761e84-5a4c-40a3-be2c-21e1543bba72"
   },
   "outputs": [],
   "source": [
    "!curl \"https://i.insider.com/56e7f946dd0895595d8b4792?width=700&format=jpeg&auto=webp\" --output go.jpg\n",
    "!curl \"https://upload.wikimedia.org/wikipedia/commons/e/ef/MRI_Head_Brain_Normal.jpg\" --output brain.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "mqF1_3N7m7K5",
    "outputId": "5fd6e27b-bced-47cd-f14b-d51ebbb0b350"
   },
   "outputs": [],
   "source": [
    "go = imread('go.jpg')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"A game of GO\")\n",
    "plt.imshow(go)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the colored image to gray-scale by combining 3 R, G, and B channels to one.\n",
    "\n",
    "This can be conveniently done with the \"skimage.color.rgb2gray\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "sbahXhSGqDcJ",
    "outputId": "00798d86-ba4d-48ef-e7f7-e6db56390db3"
   },
   "outputs": [],
   "source": [
    "go_gray = rgb2gray(go)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.gray()\n",
    "plt.title(\"A game of GO in gray-scale\")\n",
    "plt.imshow(go_gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Let's define some helper functions used for the rest of the assignment - [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tEIoZUPsPv-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_student_vs_scipy(image, kernel, student_f, scipy_f):\n",
    "    '''\n",
    "    Wrapper function that computes convolution using both students and scipy version and plots both results side-by-side for comparison.\n",
    "\n",
    "        Parameters:\n",
    "                image (array): 2-D input image/signal\n",
    "                kernel (array): 2-D convolution kernel/signal\n",
    "                student_f (function): the student's own convolution function\n",
    "                scipy_f (function): the scipy convolution function\n",
    "\n",
    "        Returns:\n",
    "                None\n",
    "    '''\n",
    "    return\n",
    "\n",
    "# check the difference in execution time between your implementation and numpy/scipy versions (refer to Labs for timing-related code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Study the construction of the given filters/kernels - [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBLemiX9pS2E"
   },
   "outputs": [],
   "source": [
    "prewitt_y = np.array([[-1., -1., -1.],\n",
    "                      [0.,0.,0.],\n",
    "                      [1.,1.,1.]])\n",
    "prewitt_x = prewitt_y.T # transpose operator\n",
    "\n",
    "sobel_y = np.array([[-1.,-2.,-1.],\n",
    "                    [0.,0.,0.],\n",
    "                    [1.,2.,1.]])\n",
    "sobel_x = sobel_y.T # transpose operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the effect of the two filters.\n",
    "\n",
    "Do you notice any difference?\n",
    "\n",
    "Can you give an explanation?\n",
    "\n",
    "**Your Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the wrapper function to visually check the effect of the filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "pq35F3afpUEs",
    "outputId": "a24c27b1-e3d4-41a2-cef6-b14f4328ffe3"
   },
   "outputs": [],
   "source": [
    "student_f = conv2d\n",
    "scipy_f = scipy.signal.convolve2d\n",
    "\n",
    "plot_student_vs_scipy(go_gray, prewitt_x, student_f, scipy_f)\n",
    "plot_student_vs_scipy(go_gray, prewitt_y, student_f, scipy_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "Uf6DQit5tICP",
    "outputId": "fb7053aa-1d68-40ab-9d20-5da76c00982a"
   },
   "outputs": [],
   "source": [
    "plot_student_vs_scipy(go_gray, sobel_x, student_f, scipy_f)\n",
    "plot_student_vs_scipy(go_gray, sobel_y, student_f, scipy_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Design a new filter/kernel and explain what its effect is - [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make a new 3 by 3 edge detection filter similar to the ones above?\n",
    "\n",
    "Hint: make sure the sum of all elements in your filter is 0, so that the result image has the same overall magnitude as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_filter = np.array([[0., 0., 0.],\n",
    "                        [0., 0., 0.],\n",
    "                        [0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "lHgBsRzJtd1l",
    "outputId": "6ebe21d4-3557-42e9-d94f-8556e700d6e2"
   },
   "outputs": [],
   "source": [
    "plot_student_vs_scipy(go_gray, your_filter, student_f, scipy_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise] Combine the two orientations of the non-symmetrical filters by applying pythagorean addition - [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode for combining filters f1 and f2 to get a new filter f3:\n",
    "```\n",
    "f3 = sqrt(f1^2 + f2^2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghzdjSgupVWL"
   },
   "outputs": [],
   "source": [
    "def combine_filter(f1, f2):\n",
    "    '''\n",
    "    Combines f1 and f2 using above pseudocode.\n",
    "\n",
    "        Parameters:\n",
    "                f1 (array): filter 1\n",
    "                f2 (array): filter 2\n",
    "\n",
    "        Returns:\n",
    "                f3 (array): filter 3\n",
    "    '''    \n",
    "    return f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "NdE7taBNuSdF",
    "outputId": "1d02520f-5f1d-4fc7-d0a0-e87c826e3d5c"
   },
   "outputs": [],
   "source": [
    "sobel_combined = combine_filter(sobel_y, sobel_x)\n",
    "plot_student_vs_scipy(go_gray, sobel_combined, student_f, scipy_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prewitt_combined = combine_filter(prewitt_y, prewitt_x)\n",
    "plot_student_vs_scipy(go_gray, prewitt_combined, student_f, scipy_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise] Apply 1) Sobel, 2) Prewitt, and 3) their respective combined filters to the brain image and plot the results - [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOmOm1C8vVeh"
   },
   "outputs": [],
   "source": [
    "brain = rgb2gray(imread(\"brain.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "BIOE488_convolution_edge_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "353902f3f2f769574ee6d5e609f500cb3c8385ac61494244183cc0b6ad3e28b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
